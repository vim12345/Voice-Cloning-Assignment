{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Voice Cloning Assignment (Colab)\n", "\n", "**Reference tutorial**: https://www.youtube.com/watch?v=3iqvBEGS2So  \n", "**Paths**: (A) TTS fine\u2011tune (XTTS\u2011v2), (B) Voice conversion (RVC)\n", "\n", "\u26a0\ufe0f Ethics: Only use voices you have rights to. Label synthetic audio.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# GPU check\n", "import torch, subprocess, os, json\n", "print('CUDA available:', torch.cuda.is_available())\n", "if torch.cuda.is_available():\n", "    print('GPU:', torch.cuda.get_device_name(0))\n", "    print('Capability:', torch.cuda.get_device_capability(0))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Environment setup\n", "Installs core deps. Re-run on every new Colab session."]}, {"cell_type": "code", "metadata": {}, "source": ["!pip -q install torch torchaudio --index-url https://download.pytorch.org/whl/cu121\n", "!pip -q install unsloth transformers datasets accelerate peft bitsandbytes\n", "!pip -q install librosa soundfile pydub faster-whisper jiwer speechbrain\n", "!pip -q install TTS  # Coqui TTS (XTTS\u2011v2)\n", "import os\n", "os.makedirs('/content/outputs/samples', exist_ok=True)\n", "os.makedirs('/content/datasets', exist_ok=True)\n", "os.makedirs('/content/logs', exist_ok=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Data upload / mount\n", "Upload WAV/MP3 of your voice (minutes \u2192 hours). Optionally mount Drive."]}, {"cell_type": "code", "metadata": {}, "source": ["from google.colab import files\n", "print('Upload one or more long recordings (or a folder after zipping).')\n", "uploads = files.upload()  # choose audio files\n", "list(uploads.keys())"]}, {"cell_type": "code", "metadata": {}, "source": ["# Optional: mount Drive if your data lives there\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Preprocess (resample + split by silence)\n", "Produces 10\u201320s chunks under `/content/datasets/wavs`."]}, {"cell_type": "code", "metadata": {}, "source": ["import os\n", "os.makedirs('/content/datasets/wavs', exist_ok=True)\n", "!python scripts/prepare_data.py --src /content --out /content/datasets/wavs --sr 22050\n", "len(os.listdir('/content/datasets/wavs'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) (Optional) Transcribe with Whisper \u2192 CSV\n", "Creates `/content/datasets/train.csv` with `audio_path,text` for TTS fine\u2011tune."]}, {"cell_type": "code", "metadata": {}, "source": ["!python scripts/transcribe_with_whisper.py --wav_dir /content/datasets/wavs --out_csv /content/datasets/train.csv --model_size small\n", "import pandas as pd\n", "pd.read_csv('/content/datasets/train.csv').head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Baseline: Zero\u2011shot cloning (XTTS\u2011v2)\n", "Generate speech using a short **reference** audio of your target speaker."]}, {"cell_type": "code", "metadata": {}, "source": ["from TTS.api import TTS\n", "import glob, os\n", "ref = sorted(glob.glob('/content/datasets/wavs/*.wav'))[:5]  # few clips as reference\n", "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\")\n", "text = \"This is a baseline zero-shot voice clone generated with XTTS version two.\"\n", "out_path = \"/content/outputs/samples/xtts_zeroshot.wav\"\n", "tts.tts_to_file(text=text, file_path=out_path, speaker_wav=ref, language=\"en\")\n", "out_path"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6A) Path A \u2014 XTTS\u2011v2 fine\u2011tuning (example)\n", "This is heavier and benefits from **2\u20133h** of clean speech + transcripts.\n", "We provide a **config skeleton** at `config/xtts_finetune_config.yaml`. Update file paths then run below."]}, {"cell_type": "code", "metadata": {}, "source": ["# Example training command (adjust for your dataset)\n", "!tts --config_path config/xtts_finetune_config.yaml --train\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6B) Path B \u2014 RVC (Retrieval\u2011based Voice Conversion)\n", "Clone the official WebUI and train a small model. Works without transcripts."]}, {"cell_type": "code", "metadata": {}, "source": ["!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI /content/rvc\n", "%cd /content/rvc\n", "!pip -q install -r requirements.txt\n", "# Minimal dataset prep: copy your clips\n", "!mkdir -p /content/rvc/datasets/wavs && cp -r /content/datasets/wavs/* /content/rvc/datasets/wavs/\n", "print('Now, in the left panel or with WebUI, you can run preprocessing/training. Documentation is in the repo README.')\n", "%cd /content\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7) Evaluation: 30s A/B and similarity score\n", "Pick one original chunk and one cloned output."]}, {"cell_type": "code", "metadata": {}, "source": ["import glob\n", "orig = sorted(glob.glob('/content/datasets/wavs/*.wav'))[0]\n", "cloned = '/content/outputs/samples/xtts_zeroshot.wav'  # or your fine\u2011tuned/RVC output\n", "!python scripts/generate_ab_sample.py --original $orig --cloned $cloned --out /content/outputs/samples/ab_30s.wav\n", "!python scripts/similarity_ecapa.py --a $orig --b $cloned\n", "print('A/B written to: /content/outputs/samples/ab_30s.wav')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8) Logging (fill templates)\n", "Open and edit the templates under `reports/templates/`.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}